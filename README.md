# ğŸš¢ PROYECTO TITANIC - APRENDIZAJE DE DATA SCIENCE

## El desafÃ­o
El hundimiento del Titanic es uno de los naufragios mÃ¡s infames de la historia.

El 15 de abril de 1912, durante su viaje inaugural, el ampliamente considerado â€œinsumergibleâ€ RMS Titanic se hundiÃ³ tras chocar con un iceberg. Desafortunadamente, no habÃ­a suficientes botes salvavidas para todos a bordo, lo que provocÃ³ la muerte de 1.502 de los 2.224 pasajeros y tripulantes.

Si bien hubo cierto elemento de suerte involucrado en la supervivencia, parece que algunos grupos de personas tenÃ­an mÃ¡s probabilidades de sobrevivir que otros.

## Diccionario de datos
| **Variable**     | **DefiniciÃ³n**                        | **Clave / DescripciÃ³n**                                                   |
| ---------------- | ------------------------------------- | ------------------------------------------------------------------------- |
| **supervivencia** | Supervivencia del pasajero            | 0 = No, 1 = SÃ­                                                            |
| **clasep**       | Clase de billete                      | 1 = 1Âª clase, 2 = 2Âª clase, 3 = 3Âª clase                                  |
| **sexo**         | Sexo del pasajero                     | â€”                                                                         |
| **edad**         | Edad en aÃ±os                          | Fraccionaria si es menor que 1; si es estimada, se representa como `xx.5` |
| **sibsp**        | NÃºmero de hermanos / cÃ³nyuges a bordo | â€”                                                                         |
| **parch**        | NÃºmero de padres / hijos a bordo      | â€”                                                                         |
| **billete**      | NÃºmero de billete del pasajero        | â€”                                                                         |
| **tarifa**       | Tarifa de pasajero                    | â€”                                                                         |
| **cabina**       | NÃºmero de cabina                      | â€”                                                                         |
| **embarcado**    | Puerto de embarque                    | C = Cherburgo, Q = Queenstown, S = Southampton                            |


### **Notas variables**
**clasep**: Un indicador del estatus socioeconÃ³mico (NSE)
- 1o = Superior
- 2do = Medio
- 3o = Inferior

**edad**: La edad es fraccionaria si es menor que 1. Si se estima la edad, Â¿tiene la forma de xx.5

**sibsp**: El conjunto de datos define las relaciones familiares de esta manera...
Hermano = hermano, hermana, hermanastro, hermanastra
CÃ³nyuge = marido, mujer (las amantes y los prometidos fueron ignorados)

**parch**: El conjunto de datos define las relaciones familiares de esta manera...
- Padre = madre, padre
- NiÃ±o = hija, hijo, hijastra, hijastro 
- Algunos niÃ±os viajaban sÃ³lo con una niÃ±era, por lo tanto parch=0 para ellos.


## ğŸ“‹ Â¿QuÃ© es este proyecto?

Mi primer proyecto prÃ¡ctico de **Data Science y Machine Learning** usando el dataset de Kaggle: [Titanic - Machine Learning from Disaster](https://www.kaggle.com/c/titanic).

## **Objetivo:** 
En este desafÃ­o, le pedimos que construya un modelo predictivo que responda a la pregunta: â€œÂ¿quÃ© tipo de personas tenÃ­an mÃ¡s probabilidades de sobrevivir?â€ utilizando datos de pasajeros (es decir, nombre, edad, sexo, clase socioeconÃ³mica, etc.).

**Nivel:** Principiante â†’ BÃ¡sico  
**Tiempo estimado:** 15-25 horas  
**Dataset:** 891 pasajeros (entrenamiento) + 418 pasajeros (prueba)

---

## ğŸ¯ Â¿QuÃ© aprenderÃ© REALMENTE con este proyecto?

### âœ… **LO QUE DOMINARÃ‰:**

**1. AnÃ¡lisis Exploratorio (EDA)**
- Cargar datos con pandas
- Usar `.head()`, `.info()`, `.describe()`
- Identificar tipos de variables (numÃ©ricas, categÃ³ricas)
- Detectar valores faltantes
- Crear visualizaciones bÃ¡sicas (histogramas, boxplots, barras)
- Encontrar patrones relacionados con supervivencia

**2. Limpieza de Datos**
- Detectar y contar valores faltantes
- Decidir estrategias de imputaciÃ³n (media, mediana, moda)
- Rellenar valores faltantes sin crear data leakage
- Eliminar columnas irrelevantes

**3. Feature Engineering BÃ¡sico**
- Extraer informaciÃ³n Ãºtil (tÃ­tulo del nombre)
- Combinar variables existentes (tamaÃ±o de familia)
- Crear variables binarias (viaja solo/acompaÃ±ado)
- Agrupar variables continuas en categorÃ­as (bins de edad)

**4. Encoding de Variables CategÃ³ricas**
- One-Hot Encoding para nominales (gÃ©nero, puerto)
- Ordinal Encoding para variables con orden (clase social)
- Entender cuÃ¡ndo usar cada mÃ©todo

**5. Modelado BÃ¡sico**
- Separar datos en train/test correctamente
- Entrenar 3-4 modelos: Logistic Regression, Decision Tree, Random Forest
- Evaluar con accuracy y confusion matrix
- Hacer predicciones en test set

**6. Submission a Kaggle**
- Crear archivo de predicciones en formato correcto
- Subir a Kaggle y obtener score pÃºblico
- Entender el proceso completo de una competencia

### ğŸŸ¡ **LO QUE VERÃ‰ PERO NO DOMINARÃ‰:**

- Cross-validation (k-fold)
- Grid Search bÃ¡sico para optimizaciÃ³n
- Feature importance
- Escalado de variables (StandardScaler)
- MÃ¡s mÃ©tricas: precision, recall, F1-score

*Estas tÃ©cnicas las verÃ© y usarÃ©, pero necesito mÃ¡s proyectos para dominarlas*

## ğŸ“ Â¿QuÃ© nivel tendrÃ© despuÃ©s del proyecto?

**ANTES:** Principiante absoluto en ML  
**DESPUÃ‰S:** BÃ¡sico - Junior

### PodrÃ©:
âœ… Cargar y explorar datasets con pandas  
âœ… Limpiar datos bÃ¡sicos  
âœ… Entrenar modelos simples de clasificaciÃ³n  
âœ… Evaluar modelos correctamente  
âœ… Completar el flujo completo de un proyecto de ML  
âœ… Entender la lÃ³gica de Data Science  

**TendrÃ© bases sÃ³lidas para seguir aprendiendo.**


## ğŸ“‚ Estructura del Proyecto
```
Ejercicio Titanic/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales
â”‚   â”‚   â”œâ”€â”€ train.csv          # 891 pasajeros
â”‚   â”‚   â””â”€â”€ test.csv           # 418 pasajeros
â”‚   â””â”€â”€ processed/              # Datos procesados
â”‚
â”œâ”€â”€ notebooks/                  # AnÃ¡lisis paso a paso
â”‚   â”œâ”€â”€ 01_eda.ipynb           # ExploraciÃ³n
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb  # Limpieza
â”‚   â”œâ”€â”€ 03_modeling.ipynb       # Modelos
â”‚   â””â”€â”€ 04_submission.ipynb     # PredicciÃ³n final
â”‚
â”œâ”€â”€ src/                        # Funciones reutilizables
â”œâ”€â”€ models/                     # Modelos guardados
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š Progreso

- [x] Setup del proyecto
- [x] Carga de datos inicial
- [ ] EDA completo
- [ ] Limpieza de datos
- [ ] Feature engineering
- [ ] Entrenamiento de modelos
- [ ] Submission a Kaggle
- [ ] Score objetivo: >75% accuracy (realista para primer intento)

---
## ğŸ’­ Reflexiones

### Â¿Por quÃ© este proyecto?

- Dataset pequeÃ±o y manejable para aprender
- Problema clÃ¡sico con mucha documentaciÃ³n
- EnseÃ±a el flujo completo de ML
- Ideal para construir fundamentos sÃ³lidos

### Â¿QuÃ© sigue despuÃ©s?

1. **House Prices** (Kaggle) - Feature engineering avanzado
2. **Customer Churn** - Datos desbalanceados
3. **Proyecto con texto o imÃ¡genes** - Nuevas tÃ©cnicas

---

## ğŸ“ Nota Importante

**Este es mi PRIMER proyecto de ML.** 

No pretende ser perfecto ni innovador. El objetivo es:
- âœ… Aprender haciendo
- âœ… Entender conceptos fundamentales
- âœ… Cometer errores y aprender de ellos
- âœ… Documentar mi proceso de aprendizaje
- âœ… Tener un punto de partida sÃ³lido

*La excelencia viene con la prÃ¡ctica. Esto es solo el inicio.*